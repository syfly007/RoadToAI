强化学习任务对应了四元组E = (X,A,P,R),



长期累积奖赏

- T步累积奖赏
- γ折扣累积奖赏



## 强化学习与监督学习的差别

若将这里的"状态"对应为监督学习中的"示例"、"动作"对应为"标记"，则可看出，强化学习中的"**策略**"实际上就相当于监督学习中的"**分类器**"(当动作是离散的)或"**回归器**"(当动作是连续的），模型的形式并无差别.但不同的是，在强化学习中并没有监督学习中的有标记样本(即"示例·标记"对)，换言之，没有人直接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过"反思"之前的动作是否正确来进行学习.因此，强化学习在某种意义上可看作具有**"延迟标记信息"的监督学习问题**.



策略迭代算法估计的是状态值函数V

最终的策略是通过状态.动作值函数Q来获得



