{"./":{"url":"./","title":"简介","keywords":"","body":"简介 ​ 网上的AI相关资料汗牛充栋，再多再好，也都是别人的，都不如自己动手总结，才能内化成自己的。 ​ 这本书是本人对人工智能的学习经验总结，主要为了帮助自己整理相关知识点，以及提供一点个人对人工智能的洞见。如果有幸被您读到，也希望能帮助到您。如果发现勘误，或者想与我讨论，可以通过如下方式联系我。 联系方式： 微信号:syfly007 email:syfly007@163.com github:https://github.com/syfly007 "},"part1/linearAlgebra.html":{"url":"part1/linearAlgebra.html","title":"线性代数","keywords":"","body":"整理下线性代数的基本概念： 标量：一个实数。如：0，1，2.1等。 向量：一组有序数组。分为行向量和列向量，如果不加说明，一般指列向量。 ​ \\vec x=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} 矩阵：二维数组，可以看作多个列向量或行向量组成。向量也可以看作矩阵的列数或行数为1时的特殊情况。 A = \\begin{bmatrix} a_{11} & \\cdots & a_{1n}\\\\ \\vdots & \\ddots & \\vdots\\\\ a_{m1} & \\cdots & a_{mn} \\end{bmatrix} 矩阵的转置： "},"part1/probability.html":{"url":"part1/probability.html","title":"概率论","keywords":"","body":"贝叶斯公式 P ( h | D ) = \\frac { P ( D | h ) P ( h ) } { P ( D ) } \\int_{-\\infty}^\\infty g(x) dx "},"part2/logistic.html":{"url":"part2/logistic.html","title":"Logistic 回归","keywords":"","body":"Logistic回归 logistic回归，也叫逻辑回归，虽然也叫回归，但是用来做分类的。 主要思想是：根据数据，对分类边界线建立回归公式，以此进行分类。 概念须知 回归 有一些数据点，我们要对这些数据点进行拟合（这条直线成为最佳拟合直线），这个拟合的过程就叫做回归（regression)。 Sigmoid/Logistic 函数 公式： \\sigma ( t ) = \\frac { 1} { 1+ e ^ { - t } } 函数图： 参考资料： https://github.com/apachecn/MachineLearning/blob/master/docs/5.Logistic%E5%9B%9E%E5%BD%92.md "},"part4/score.html":{"url":"part4/score.html","title":"评价指标：accuracy, recall, precision, F1","keywords":"","body":"评价标准 预测矩阵： 实际为真 实际为假 预测为真 true positive (TP) false positive (FP) 预测为假 false negative(FN) true negative(TN) 机器学习有多种评价指标，常用的有准确率（accuracy）、查准率（precision）、查全率（recall）和 F1-score。 准确率（accuracy） = （TP + TN)/(TP + TN + FP + FN) ​ 这里predict表示预测正确的样本数，total表示总样本数。 ​ 准确率（accuracy）应该是最常用的评价指标，这种方式通常是可行的，但是有些特殊情况下也会遇到问题。比如有个雷达预测数据集，有99个为真，1个为假，如果模型是直接统统预测为真，准确率就为99%，看起来准确率很高，但显然不是我们想要的模型。 ​ 这时就需要另外2个指标： 精确率(precision) = TP/(TP+FP) 召回率(recall) = TP/(TP+FN) ​ 为了便于形象理解，请看如下的文氏图。 ​ 其实就是分母不同，precision的分母是全部预测为正类的样本数，recall是全部正样本数。 ​ 在信息检索领域，精确率和召回率又被称为查准率和查全率， ​ 查准率＝检索出的相关信息量 / 检索出的信息总量 ​ 查全率＝检索出的相关信息量 / 系统中的相关信息总量 ​ 通俗的说，precison表示预测的样本中有多少是正确的，recall表示所有正样本中有多少是正确的。 ​ 有的时候，我们要同时衡量recall和precision，于是对它们做调和平均数(Harmonic mean)。 F1 = \\frac {2⋅Precison⋅Recall} {Precision + Recall} ​ 可以看到，recall 体现了分类模型对正样本的识别能力，recall 越高，说明模型对正样本的识别能力越强，precision 体现了模型对负样本的区分能力，precision越高，说明模型对负样本的区分能力越强。F1-score 是两者的综合。F1-score 越高，说明分类模型越稳健。 ​ 有的时候，我们对recall 与 precision 赋予不同的权重，表示对分类模型的偏好： F_{β}=\\frac{(1+β^2)TP}{(1+β^2)TP+β^2FN+FP}=\\frac{(1+β^2)⋅Precision⋅Recall}{β^2⋅Precision+Recall} ​ 可以看到，当 β=1，那么Fβ就退回到F1了，β其实反映了模型分类能力的偏好，β>1 的时候，precision的权重更大，为了提高Fβ，我们希望precision 越小，而recall 应该越大，说明模型更偏好于提升recall，意味着模型更看重对正样本的识别能力； 而 β 参考资料： https://www.wikiwand.com/en/F1_score https://blog.csdn.net/matrix_space/article/details/50384518 https://www.zhihu.com/question/19645541 "}}